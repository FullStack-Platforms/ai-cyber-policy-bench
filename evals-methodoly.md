Evals should fit the following types:
- Accuracy
- Technical Writing

Accuracy questions are those that verify the correctness of the model's output against the ground truth. Technical writing questions are verified to ensure they accurately cite the ground truth, and accurately translated the context into practical actions and behaviors, not just words.

We are benchmarking the following and should be able to represent our findings in the results. 
- Evaluating LLM models on our eval questions without being provided additional context 
- Evaluating LLM models on our eval questions, and providing them the raw relevant markdown files for context
- Evaluating LLM models on our eval questions, and providing them the relevant context via a vector database 
